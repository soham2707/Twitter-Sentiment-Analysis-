{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nimport torch.nn.functional as F\nfrom transformers import RobertaTokenizer, RobertaConfig,AdamW, RobertaForSequenceClassification,get_linear_schedule_with_warmup\n\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,classification_report\n# Import and evaluate each test batch using Matthew's correlation coefficient\nfrom sklearn.metrics import accuracy_score,matthews_corrcoef\n\nfrom tqdm import tqdm, trange,tnrange,tqdm_notebook\nimport random\nimport os\nimport io\n% matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-09-09T14:57:35.531366Z","iopub.execute_input":"2021-09-09T14:57:35.531791Z","iopub.status.idle":"2021-09-09T14:57:43.889317Z","shell.execute_reply.started":"2021-09-09T14:57:35.5317Z","shell.execute_reply":"2021-09-09T14:57:43.887607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ROBERTA - Twitter Sentiment Classifier","metadata":{}},{"cell_type":"markdown","source":"# **Identify and specify the GPU as the device, later in training loop we will load data into device**","metadata":{}},{"cell_type":"code","source":"# identify and specify the GPU as the device, later in training loop we will load data into device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_gpu = torch.cuda.device_count()\ntorch.cuda.get_device_name(0)\n\nSEED = 19\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif device == torch.device(\"cuda\"):\n    torch.cuda.manual_seed_all(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T14:58:15.35309Z","iopub.execute_input":"2021-09-09T14:58:15.353561Z","iopub.status.idle":"2021-09-09T14:58:15.41967Z","shell.execute_reply.started":"2021-09-09T14:58:15.353528Z","shell.execute_reply":"2021-09-09T14:58:15.418425Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Read File**","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/twitter-sentiment-dataset/Twitter_Data.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-09T14:58:30.279517Z","iopub.execute_input":"2021-09-09T14:58:30.279886Z","iopub.status.idle":"2021-09-09T14:58:30.815585Z","shell.execute_reply.started":"2021-09-09T14:58:30.279853Z","shell.execute_reply":"2021-09-09T14:58:30.814382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Checking Null Value**","metadata":{}},{"cell_type":"code","source":"df_train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T14:58:47.440423Z","iopub.execute_input":"2021-09-09T14:58:47.440821Z","iopub.status.idle":"2021-09-09T14:58:47.482179Z","shell.execute_reply.started":"2021-09-09T14:58:47.440787Z","shell.execute_reply":"2021-09-09T14:58:47.480607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T14:58:58.952564Z","iopub.execute_input":"2021-09-09T14:58:58.952961Z","iopub.status.idle":"2021-09-09T14:58:58.971771Z","shell.execute_reply.started":"2021-09-09T14:58:58.95293Z","shell.execute_reply":"2021-09-09T14:58:58.970419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Target Distribution**","metadata":{}},{"cell_type":"code","source":"df_train['category'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T14:59:11.943937Z","iopub.execute_input":"2021-09-09T14:59:11.944349Z","iopub.status.idle":"2021-09-09T14:59:11.959739Z","shell.execute_reply.started":"2021-09-09T14:59:11.944317Z","shell.execute_reply":"2021-09-09T14:59:11.958189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['category'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T14:59:25.079997Z","iopub.execute_input":"2021-09-09T14:59:25.080524Z","iopub.status.idle":"2021-09-09T14:59:25.095817Z","shell.execute_reply.started":"2021-09-09T14:59:25.080491Z","shell.execute_reply":"2021-09-09T14:59:25.094211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Removing Null value**","metadata":{}},{"cell_type":"code","source":"df_train = df_train[~df_train['category'].isnull()]","metadata":{"execution":{"iopub.status.busy":"2021-09-09T14:59:38.504063Z","iopub.execute_input":"2021-09-09T14:59:38.504502Z","iopub.status.idle":"2021-09-09T14:59:38.52356Z","shell.execute_reply.started":"2021-09-09T14:59:38.504469Z","shell.execute_reply":"2021-09-09T14:59:38.522388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_train[~df_train['clean_text'].isnull()]","metadata":{"execution":{"iopub.status.busy":"2021-09-09T14:59:59.569579Z","iopub.execute_input":"2021-09-09T14:59:59.569957Z","iopub.status.idle":"2021-09-09T14:59:59.604946Z","shell.execute_reply.started":"2021-09-09T14:59:59.569923Z","shell.execute_reply":"2021-09-09T14:59:59.603852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Target Encoding**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\ndf_train['category_1'] = labelencoder.fit_transform(df_train['category'])","metadata":{"execution":{"iopub.status.busy":"2021-09-09T15:00:08.449032Z","iopub.execute_input":"2021-09-09T15:00:08.449439Z","iopub.status.idle":"2021-09-09T15:00:08.467983Z","shell.execute_reply.started":"2021-09-09T15:00:08.449406Z","shell.execute_reply":"2021-09-09T15:00:08.466926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[['category','category_1']].drop_duplicates(keep='first')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T15:00:26.977583Z","iopub.execute_input":"2021-09-09T15:00:26.977982Z","iopub.status.idle":"2021-09-09T15:00:27.00518Z","shell.execute_reply.started":"2021-09-09T15:00:26.977949Z","shell.execute_reply":"2021-09-09T15:00:27.003712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.rename(columns={'category_1':'label'},inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T15:00:42.568556Z","iopub.execute_input":"2021-09-09T15:00:42.568922Z","iopub.status.idle":"2021-09-09T15:00:42.576058Z","shell.execute_reply.started":"2021-09-09T15:00:42.56889Z","shell.execute_reply":"2021-09-09T15:00:42.574601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Preperation For Roberta Model**","metadata":{}},{"cell_type":"code","source":"## create label and sentence list\nsentences = df_train.clean_text.values\n\n#check distribution of data based on labels\nprint(\"Distribution of data based on labels: \",df_train.label.value_counts())\n\n# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway. \n# In the original paper, the authors used a length of 512.\nMAX_LEN = 256\n\n## Import ROBERTA tokenizer, that is used to convert our text into tokens that corresponds to ROBERTA library\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base',do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T15:02:49.367561Z","iopub.execute_input":"2021-09-09T15:02:49.367965Z","iopub.status.idle":"2021-09-09T15:02:55.013642Z","shell.execute_reply.started":"2021-09-09T15:02:49.367932Z","shell.execute_reply":"2021-09-09T15:02:55.011547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids = [tokenizer.encode(sent, add_special_tokens=True,\n                              max_length=MAX_LEN,\n                              pad_to_max_length=True,truncation=True) for sent in sentences]","metadata":{"execution":{"iopub.status.busy":"2021-09-09T15:03:24.210312Z","iopub.execute_input":"2021-09-09T15:03:24.21069Z","iopub.status.idle":"2021-09-09T15:04:35.049702Z","shell.execute_reply.started":"2021-09-09T15:03:24.210656Z","shell.execute_reply":"2021-09-09T15:04:35.048558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = df_train.label.values\n\nprint(\"Actual sentence before tokenization: \",sentences[2])\nprint(\"Encoded Input from dataset: \",input_ids[2])\n\n## Create attention mask\nattention_masks = []\n## Create a mask of 1 for all input tokens and 0 for all padding tokens\nattention_masks = [[float(i>0) for i in seq] for seq in input_ids]\nprint(attention_masks[2])","metadata":{"execution":{"iopub.status.busy":"2021-09-09T15:05:04.252052Z","iopub.execute_input":"2021-09-09T15:05:04.252447Z","iopub.status.idle":"2021-09-09T15:05:13.17969Z","shell.execute_reply.started":"2021-09-09T15:05:04.252414Z","shell.execute_reply":"2021-09-09T15:05:13.178501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_inputs,validation_inputs,train_labels,validation_labels = train_test_split(input_ids,labels,random_state=41,test_size=0.1)\ntrain_masks,validation_masks,_,_ = train_test_split(attention_masks,input_ids,random_state=41,test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T15:05:36.24232Z","iopub.execute_input":"2021-09-09T15:05:36.242707Z","iopub.status.idle":"2021-09-09T15:05:36.453686Z","shell.execute_reply.started":"2021-09-09T15:05:36.242674Z","shell.execute_reply":"2021-09-09T15:05:36.452522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert all our data into torch tensors, required data type for our model\ntrain_inputs = torch.tensor(train_inputs)\nvalidation_inputs = torch.tensor(validation_inputs)\ntrain_labels = torch.tensor(train_labels)\nvalidation_labels = torch.tensor(validation_labels)\ntrain_masks = torch.tensor(train_masks)\nvalidation_masks = torch.tensor(validation_masks)\n\n# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\nbatch_size = 32\n\n# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n# with an iterator the entire dataset does not need to be loaded into memory\ntrain_data = TensorDataset(train_inputs,train_masks,train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data,sampler=train_sampler,batch_size=batch_size)\n\nvalidation_data = TensorDataset(validation_inputs,validation_masks,validation_labels)\nvalidation_sampler = RandomSampler(validation_data)\nvalidation_dataloader = DataLoader(validation_data,sampler=validation_sampler,batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T15:06:12.210709Z","iopub.execute_input":"2021-09-09T15:06:12.211198Z","iopub.status.idle":"2021-09-09T15:06:12.553859Z","shell.execute_reply.started":"2021-09-09T15:06:12.211139Z","shell.execute_reply":"2021-09-09T15:06:12.552428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Lets see how the training data looks like**","metadata":{}},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2021-09-09T15:06:22.682184Z","iopub.execute_input":"2021-09-09T15:06:22.682569Z","iopub.status.idle":"2021-09-09T15:06:22.757586Z","shell.execute_reply.started":"2021-09-09T15:06:22.682536Z","shell.execute_reply":"2021-09-09T15:06:22.755964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Load RobertaForSequenceClassification, the pretrained ROBERTA model with a single linear classification layer on top**","metadata":{}},{"cell_type":"code","source":"# Load RobertaForSequenceClassification, the pretrained ROBERTA model with a single linear classification layer on top.num_lables=3 because we have 3 class \nmodel = RobertaForSequenceClassification.from_pretrained('roberta-base',num_labels=3).to(device)\n\n# Parameters:\nlr = 2e-5\nadam_epsilon = 1e-8\n\n# Number of training epochs (authors recommend between 2 and 4)\nepochs = 3\n\nnum_warmup_steps = 0\nnum_training_steps = len(train_dataloader)*epochs\n\n### In Transformers, optimizer and schedules are splitted and instantiated like this:\noptimizer = AdamW(model.parameters(), lr=lr,eps=adam_epsilon,correct_bias=False)  # To reproduce AdamW specific behavior set correct_bias=False\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)  # PyTorch scheduler","metadata":{"execution":{"iopub.status.busy":"2021-09-09T15:12:44.116997Z","iopub.execute_input":"2021-09-09T15:12:44.117413Z","iopub.status.idle":"2021-09-09T15:13:14.497759Z","shell.execute_reply.started":"2021-09-09T15:12:44.11738Z","shell.execute_reply":"2021-09-09T15:13:14.496614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Train Loop**","metadata":{}},{"cell_type":"code","source":"## Store our loss and accuracy for plotting\ntrain_loss_set = []\nlearning_rate = []\n\n# Gradients gets accumulated by default\nmodel.zero_grad()\n\n# tnrange is a tqdm wrapper around the normal python range\nfor _ in tnrange(1,epochs+1,desc='Epoch'):\n  print(\"<\" + \"=\"*22 + F\" Epoch {_} \"+ \"=\"*22 + \">\")\n  # Calculate total loss for this epoch\n  batch_loss = 0\n\n  for step, batch in enumerate(train_dataloader):\n    # Set our model to training mode (as opposed to evaluation mode)\n    model.train()\n    \n    # Add batch to GPU\n    batch = tuple(t.to(device) for t in batch)\n    # Unpack the inputs from our dataloader\n    b_input_ids, b_input_mask, b_labels = batch\n\n    # Forward pass\n    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n    loss = outputs[0]\n    \n    # Backward pass\n    loss.backward()\n    \n    # Clip the norm of the gradients to 1.0\n    # Gradient clipping is not in AdamW anymore\n    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n    \n    # Update parameters and take a step using the computed gradient\n    optimizer.step()\n    \n    # Update learning rate schedule\n    scheduler.step()\n\n    # Clear the previous accumulated gradients\n    optimizer.zero_grad()\n    \n    # Update tracking variables\n    batch_loss += loss.item()\n\n  # Calculate the average loss over the training data.\n  avg_train_loss = batch_loss / len(train_dataloader)\n\n  #store the current learning rate\n  for param_group in optimizer.param_groups:\n    print(\"\\n\\tCurrent Learning rate: \",param_group['lr'])\n    learning_rate.append(param_group['lr'])\n    \n  train_loss_set.append(avg_train_loss)\n  print(F'\\n\\tAverage Training loss: {avg_train_loss}')\n    \n  # Validation\n\n  # Put model in evaluation mode to evaluate loss on the validation set\n  model.eval()\n\n  # Tracking variables \n  eval_accuracy,eval_mcc_accuracy,nb_eval_steps = 0, 0, 0\n\n  # Evaluate data for one epoch\n  for batch in validation_dataloader:\n    # Add batch to GPU\n    batch = tuple(t.to(device) for t in batch)\n    # Unpack the inputs from our dataloader\n    b_input_ids, b_input_mask, b_labels = batch\n    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n    with torch.no_grad():\n      # Forward pass, calculate logit predictions\n      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n    \n    # Move logits and labels to CPU\n    logits = logits[0].to('cpu').numpy()\n    label_ids = b_labels.to('cpu').numpy()\n\n    pred_flat = np.argmax(logits, axis=1).flatten()\n    labels_flat = label_ids.flatten()\n    \n    df_metrics=pd.DataFrame({'Epoch':epochs,'Actual_class':labels_flat,'Predicted_class':pred_flat})\n    \n    tmp_eval_accuracy = accuracy_score(labels_flat,pred_flat)\n    tmp_eval_mcc_accuracy = matthews_corrcoef(labels_flat, pred_flat)\n    \n    eval_accuracy += tmp_eval_accuracy\n    eval_mcc_accuracy += tmp_eval_mcc_accuracy\n    nb_eval_steps += 1\n\n  print(F'\\n\\tValidation Accuracy: {eval_accuracy/nb_eval_steps}')\n  print(F'\\n\\tValidation MCC Accuracy: {eval_mcc_accuracy/nb_eval_steps}')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T15:13:35.316884Z","iopub.execute_input":"2021-09-09T15:13:35.317296Z","iopub.status.idle":"2021-09-09T18:23:28.140045Z","shell.execute_reply.started":"2021-09-09T15:13:35.317261Z","shell.execute_reply":"2021-09-09T18:23:28.138636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## emotion labels\nlabel2int = {\n  \"Negative\": 0,\n  \"Neutral\": 1,\n  \"Positive\": 2\n}","metadata":{"execution":{"iopub.status.busy":"2021-09-09T18:24:34.97743Z","iopub.execute_input":"2021-09-09T18:24:34.977928Z","iopub.status.idle":"2021-09-09T18:24:34.990847Z","shell.execute_reply.started":"2021-09-09T18:24:34.977883Z","shell.execute_reply":"2021-09-09T18:24:34.988015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(df_metrics['Actual_class'].values, df_metrics['Predicted_class'].values, target_names=label2int.keys(), digits=len(label2int)))","metadata":{"execution":{"iopub.status.busy":"2021-09-09T18:25:13.402881Z","iopub.execute_input":"2021-09-09T18:25:13.403316Z","iopub.status.idle":"2021-09-09T18:25:13.420261Z","shell.execute_reply.started":"2021-09-09T18:25:13.403281Z","shell.execute_reply":"2021-09-09T18:25:13.419045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,classification_report\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    import itertools\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T18:25:16.280502Z","iopub.execute_input":"2021-09-09T18:25:16.280886Z","iopub.status.idle":"2021-09-09T18:25:16.292344Z","shell.execute_reply.started":"2021-09-09T18:25:16.280852Z","shell.execute_reply":"2021-09-09T18:25:16.290655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix(df_metrics['Actual_class'].values, df_metrics['Predicted_class'].values)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T18:25:20.181486Z","iopub.execute_input":"2021-09-09T18:25:20.18192Z","iopub.status.idle":"2021-09-09T18:25:20.191671Z","shell.execute_reply.started":"2021-09-09T18:25:20.181879Z","shell.execute_reply":"2021-09-09T18:25:20.190355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(cm=confusion_matrix(df_metrics['Actual_class'].values, df_metrics['Predicted_class'].values), \n                      classes=[0  ,1  ,2],\n                          normalize=True,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T18:30:28.293065Z","iopub.execute_input":"2021-09-09T18:30:28.293471Z","iopub.status.idle":"2021-09-09T18:30:28.636744Z","shell.execute_reply.started":"2021-09-09T18:30:28.29343Z","shell.execute_reply":"2021-09-09T18:30:28.635588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Conclusion**:\nHere we can see the model didn't perform well in case of negative tweet.","metadata":{}},{"cell_type":"markdown","source":"# Kindly upvote if you like it","metadata":{}}]}